{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e61137ac-c301-41d1-b7ff-d8b8b476e05f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Extracting Checkpoint, Bronze, Silver containers URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd90da21-b5d3-4ad8-82c2-2b482a5e6f7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = spark.sql(\"describe external location `checkpoints`\").select(\"url\").collect()[0][0]\n",
    "bronze = spark.sql(\"describe external location `bronze`\").select(\"url\").collect()[0][0]\n",
    "silver = spark.sql(\"describe external location `silver`\").select(\"url\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb8f49c7-0091-4a4f-9fbb-314f81bab34e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(name=\"env\",defaultValue='',label='Enter the environment in lower case')\n",
    "env = dbutils.widgets.get(\"env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "844a6639-6657-466f-b72b-7104ba0a18fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Reading the data from bronze Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c78c455e-47a7-464c-ba8a-ae98100a30a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_BronzeTrafficTable(environment):\n",
    "    print('Reading the Bronze Table Data : ',end='')\n",
    "    df_bronzeTraffic = (spark.readStream\n",
    "                    .table(f\"`{environment}_catalog`.`bronze`.raw_traffic\")\n",
    "                    )\n",
    "    print(f'Reading {environment}_catalog.bronze.raw_traffic Success!')\n",
    "    return df_bronzeTraffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c158bc94-febe-47a0-9186-0db4a7365f01",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Handing duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed7c8fbe-a598-40d2-83a3-d812d5cb80d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def remove_Dups(df):\n",
    "    print('Removing Duplicate values: ', end='')\n",
    "    df_dup = df.dropDuplicates()\n",
    "    print('Success!! ')\n",
    "    return df_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7e8e361-7e26-431b-9cbe-b9d435b602a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Handling NULL values by replacing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78030122-0435-4373-8ddc-31982f9111e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def handle_NULLs(df,columns):\n",
    "    print('Replacing NULL values on String Columns with \"Unknown\" ' , end='')\n",
    "    df_string = df.fillna('Unknown',subset= columns)\n",
    "    print('Successs!! ')\n",
    "\n",
    "    print('Replacing NULL values on Numeric Columns with \"0\" ' , end='')\n",
    "    df_clean = df_string.fillna(0,subset = columns)\n",
    "    print('Success!! ')\n",
    "\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99cde0c9-f4f7-4b62-9413-a8df55a217a9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Getting count of Electric vehicles by creating new column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05f15a1e-cdab-4c5f-97b9-ab01f34e3a5c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def ev_Count(df):\n",
    "    print('Creating Electric Vehicles Count Column : ', end='')\n",
    "    from pyspark.sql.functions import col\n",
    "    df_ev = df.withColumn('Electric_Vehicles_Count',\n",
    "                            col('EV_Car') + col('EV_Bike')\n",
    "                            )\n",
    "    \n",
    "    print('Success!! ')\n",
    "    return df_ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f17e6f14-9dfb-4da3-948c-179d08584668",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Creating columns to get Count of all motor vehicles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47e17ec0-de2f-4a27-bb31-731ab31d6e08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def Motor_Count(df):\n",
    "    print('Creating All Motor Vehicles Count Column : ', end='')\n",
    "    from pyspark.sql.functions import col\n",
    "    df_motor = df.withColumn('Motor_Vehicles_Count',\n",
    "                            col('Electric_Vehicles_Count') + col('Two_wheeled_motor_vehicles') + col('Cars_and_taxis') + col('Buses_and_coaches') + col('LGV_Type') + col('HGV_Type')\n",
    "                            )\n",
    "    \n",
    "    print('Success!! ')\n",
    "    return df_motor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b48f494-c505-4d4d-bc8e-000f7199818f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Creating Transformed Time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bce2aa6e-5ae5-49ec-8341-abff10c9ff1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_TransformedTime(df):\n",
    "    from pyspark.sql.functions import current_timestamp\n",
    "    print('Creating Transformed Time column : ',end='')\n",
    "    df_timestamp = df.withColumn('Transformed_Time',\n",
    "                      current_timestamp()\n",
    "                      )\n",
    "    print('Success!!')\n",
    "    return df_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fe5b13c-c71e-4a81-8565-3d82d292763a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Calling the functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "157f2e96-5011-445f-a003-36ddc09135e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Writing the Transformed data to Silver_Traffic Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc590ef3-e03a-4402-beff-197c8bb663ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_Traffic_SilverTable(StreamingDF,environment):\n",
    "    print('Writing the silver_traffic Data : ',end='') \n",
    "\n",
    "    write_StreamSilver = (StreamingDF.writeStream\n",
    "                .format('delta')\n",
    "                .option('checkpointLocation',checkpoint+ \"/SilverTrafficLoad/Checkpt/\")\n",
    "                .outputMode('append')\n",
    "                .queryName(\"SilverTrafficWriteStream\")\n",
    "                .trigger(availableNow=True)\n",
    "                .toTable(f\"`{environment}_catalog`.`silver`.`silver_traffic`\"))\n",
    "    \n",
    "    write_StreamSilver.awaitTermination()\n",
    "    print(f'Writing `{environment}_catalog`.`silver`.`silver_traffic` Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2ecac52-5406-4325-88b0-a8ed57b4b876",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95e40566-fb31-4af2-a517-17f734ded95a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the Bronze Table Data : Reading dev_catalog.bronze.raw_traffic Success!\nRemoving Duplicate values: Success!! \nReplacing NULL values on String Columns with \"Unknown\" Successs!! \nReplacing NULL values on Numeric Columns with \"0\" Success!! \nCreating Electric Vehicles Count Column : Success!! \nCreating All Motor Vehicles Count Column : Success!! \nCreating Transformed Time column : Success!!\nWriting the silver_traffic Data : Writing `dev_catalog`.`silver`.`silver_traffic` Success!\n"
     ]
    }
   ],
   "source": [
    "## Reading the bronze traffic data\n",
    "\n",
    "df_trafficdata = read_BronzeTrafficTable(env)\n",
    "\n",
    "# To remove duplicate rows\n",
    "\n",
    "df_dups = remove_Dups(df_trafficdata)\n",
    "\n",
    "# To raplce any NULL values\n",
    "Allcolumns =df_dups.schema.names\n",
    "df_nulls = handle_NULLs(df_dups,Allcolumns)\n",
    "\n",
    "## To get the total EV_Count\n",
    "\n",
    "df_ev = ev_Count(df_nulls)\n",
    "\n",
    "\n",
    "## To get the Total Motor vehicle count\n",
    "\n",
    "df_motor = Motor_Count(df_ev)\n",
    "\n",
    "## Calling Transformed time function\n",
    "\n",
    "df_final = create_TransformedTime(df_motor)\n",
    "\n",
    "## Writing to silver_traffic\n",
    "\n",
    "write_Traffic_SilverTable(df_final, env)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03. Silver - Traffic Transformations",
   "widgets": {
    "env": {
     "currentValue": "dev",
     "nuid": "aad65f65-3e66-4b2b-8ada-0e26a63ae2d1",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
